{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dfc0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } .end_space { min-height:0px !important; } .prompt {width: 0px; min-width: 0px; visibility: collapse } .parent{    display: grid;    grid-template-columns: 1fr 1fr;    column-gap: 5px;}    </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from libraries.utility import Utility as mutil\n",
    "from libraries.db_base import db_base\n",
    "import os\n",
    "import time\n",
    "\n",
    "from libraries.utility import Utility as mutil\n",
    "from libraries.db_base import db_base\n",
    "from libraries.db_ins_fake_data import fake_data_to_db\n",
    "from libraries.custom_excel_output import custom_excel_output\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import pandasql as psql\n",
    "from IPython.core.display import Markdown as md\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML, Markdown, Latex\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "        '.prompt {width: 0px; min-width: 0px; visibility: collapse } '\n",
    "        '.parent{'\n",
    "        '    display: grid;'\n",
    "        '    grid-template-columns: 1fr 1fr;'\n",
    "        '    column-gap: 5px;'\n",
    "        '}    '\n",
    "    '</style>'\n",
    "))\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3598d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_sesssion():\n",
    "    # Create SparkSession\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"MasterSession\") \\\n",
    "        .config(\"spark.jars\", \"/usr/share/java/sqljdbc_12.4/enu/jars/mssql-jdbc-12.4.2.jre11.jar\") \\\n",
    "        .config(\"spark.jars\", \"/usr/share/java/postgresql.jar\") \\\n",
    "        .config(\"spark.jars\", \"/usr/share/java/mysql-connector-j-8.2.0.jar\") \\\n",
    "        .getOrCreate()    \n",
    "    return spark\n",
    "\n",
    "def test_sql_server_connection(query,spark):\n",
    "    \n",
    "    #Location of database drivers\n",
    "    #postgres\n",
    "    #/usr/share/java/postgresql.jar\n",
    "    #mysql\n",
    "    #/usr/share/java/mysql-connector-j-8.2.0.jar\n",
    "    #mssql\n",
    "    #/usr/share/java/sqljdbc_12.4/enu/jars/mssql-jdbc-12.4.2.jre11.jar\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "\n",
    "    # Database connection properties\n",
    "    database_url = \"jdbc:sqlserver://mssql1:1433;databaseName=products\"\n",
    "    database_properties = {\n",
    "        \"user\": \"sa\",\n",
    "        \"password\": \"Python2028\",\n",
    "        \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\",\n",
    "        \"encrypt\": \"true\",\n",
    "        \"trustServerCertificate\": \"true\"  # Add this line        \n",
    "    }\n",
    "\n",
    "    \n",
    "    # Read data from MSSQL\n",
    "    #df = spark.read.jdbc(url=database_url, table=\"products\", properties=database_properties)\n",
    "\n",
    "    # Read data from MSSQL\n",
    "    df = spark.read.jdbc(url=database_url, table=query, properties=database_properties)\n",
    "\n",
    "    # Show the data\n",
    "    #df.show()\n",
    "    \n",
    "    # Stop the timer and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Convert elapsed time to minutes and seconds\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    \n",
    "    print(f\"Time elapsed: {minutes} minutes and {seconds} seconds\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def test_postgress_sql(query,spark):\n",
    "  \n",
    "    #Location of database drivers\n",
    "    #postgres\n",
    "    #/usr/share/java/postgresql.jar\n",
    "    #mysql\n",
    "    #/usr/share/java/mysql-connector-j-8.2.0.jar\n",
    "    #mssql\n",
    "    #/usr/share/java/sqljdbc_12.4/enu/jars/mssql-jdbc-12.4.2.jre11.jar\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    # Database connection properties\n",
    "    database_url = \"jdbc:postgresql://postsql1:5432/finance\"\n",
    "    database_properties = {\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"Python2028\",\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"encrypt\": \"true\",\n",
    "        \"trustServerCertificate\": \"true\"  # Add this line        \n",
    "    }\n",
    "    \n",
    "    # Read data from MSSQL\n",
    "    df = spark.read.jdbc(url=database_url, table=query, properties=database_properties)\n",
    "\n",
    "    # Show the data\n",
    "    #df.show()\n",
    "    \n",
    "    # Stop the timer and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Convert elapsed time to minutes and seconds\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    \n",
    "    print(f\"Time elapsed: {minutes} minutes and {seconds} seconds\")\n",
    "    return df\n",
    "\n",
    "def test_mysql_server(query,spark):\n",
    "    \n",
    "    #Location of database drivers\n",
    "    #postgres\n",
    "    #/usr/share/java/postgresql.jar\n",
    "    #mysql\n",
    "    #/usr/share/java/mysql-connector-j-8.2.0.jar\n",
    "    #mssql\n",
    "    #/usr/share/java/sqljdbc_12.4/enu/jars/mssql-jdbc-12.4.2.jre11.jar\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    # Database connection properties\n",
    "    database_url = \"jdbc:mysql://mysql1:3306/customers\"\n",
    "    database_properties = {\n",
    "        \"user\": \"root\",\n",
    "        \"password\": \"Python2028\",\n",
    "        \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "        \"encrypt\": \"true\",\n",
    "        \"trustServerCertificate\": \"true\"  # Add this line        \n",
    "    }\n",
    "    \n",
    "    # Read data from MSSQL\n",
    "    df = spark.read.jdbc(url=database_url, table=query, properties=database_properties)\n",
    "    \n",
    "    # Stop the timer and calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Convert elapsed time to minutes and seconds\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    \n",
    "    print(f\"Time elapsed: {minutes} minutes and {seconds} seconds\")\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883e67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784c70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 18 for SQL Server' : file not found (0) (SQLDriverConnect)\")\n",
      "Database : products, Connection Good: False\n",
      "Time elapsed: 0 minutes and 0 seconds\n",
      "connection to server at \"127.0.0.1\", port 5432 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "Database : finance, Connection Good: False\n",
      "Time elapsed: 0 minutes and 0 seconds\n",
      "2003 (HY000): Can't connect to MySQL server on '127.0.0.1:3306' (111)\n",
      "Database : customers, Connection Good: False\n",
      "Time elapsed: 0 minutes and 0 seconds\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+-------+-------------------+--------------------+--------------------+--------------+--------------------+------------+\n",
      "|customer_id|              f_name|              l_name|        product_name|        product_type|amt_usd|          post_date|        channel_desc|        partner_desc| location_name|        account_name|account_type|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+-------+-------------------+--------------------+--------------------+--------------+--------------------+------------+\n",
      "|        408|Brad             ...|Grimes           ...|   Wyatt's Wild Ride|Single View Movie...| $14.07|2023-05-29 05:21:56|Theatrical       ...|Myers-Zuniga     ...|    Washington|Streaming Cash Re...|     Revenue|\n",
      "|        951|Tiffany          ...|Gonzalez         ...|Debbie's Date in ...|Download         ...| $30.34|2023-04-10 08:00:30|Virtual Reality (...|Simmons-Cortez   ...|     Oceanside|Distribution Inco...|     Revenue|\n",
      "|       1172|Maria            ...|Wood             ...|    John's Great War|Single View Movie...|  $8.50|2023-04-17 04:50:49|Airlines         ...|Jones, Merritt an...|        Conway|Rental Income Rev...|     Revenue|\n",
      "|        967|Jessica          ...|Sloan            ...|Brandy's Monster ...|Bundle           ...| $10.72|2023-11-03 20:20:31|Home Video Rental...|Rowe, Walsh and J...|Fredericksburg|Distribution Inco...|     Revenue|\n",
      "|        690|Brittney         ...|Barajas          ...|   Tracy's Great War|Bundle           ...| $16.69|2023-07-08 16:52:53|Sports Networks  ...|Henderson, Johnso...|       Lincoln|Rental Income Rev...|     Revenue|\n",
      "|       1155|Edward           ...|Johnson          ...|Karen's Patriotic...|Pay TV           ...| $15.88|2023-11-25 08:25:19|Events           ...|Vega, James and C...|     Melbourne|Streaming Cash Re...|     Revenue|\n",
      "|       1075|Austin           ...|Thomas           ...|Tiffany's Amazing...|Subscription     ...| $24.81|2023-03-23 17:09:16|Cable TV Networks...|Thompson, Watson ...|       Yonkers|Theatrical Income...|     Revenue|\n",
      "|        802|David            ...|Reed             ...|Shelby's Date Wit...|Subscription     ...| $21.80|2023-05-16 09:10:09|Virtual Reality (...|Munoz, Ferrell an...|        Durham|Music Income Reve...|     Revenue|\n",
      "|       1555|Mitchell         ...|Wright           ...|Edward's Spy Thri...|Movie            ...|  $9.61|2023-06-18 11:22:13|Video Game Consol...|Steele, Mclaughli...|    Greensburg|Streaming Cash Re...|     Revenue|\n",
      "|       1555|Mitchell         ...|Wright           ...|Edward's Spy Thri...|Movie            ...|  $9.61|2023-06-17 18:45:41|Streaming Aggrega...|Brown PLC        ...|    Greensburg|Theatrical Income...|     Revenue|\n",
      "|       1257|Stephanie        ...|Smith            ...| April's Big Romance|Game             ...| $26.03|2023-04-29 07:03:40|Home Video       ...|Chavez, Holt and ...|  Cedar Rapids|Streaming Cash Re...|     Revenue|\n",
      "|       1383|Brittany         ...|Dickerson        ...|Alexandra's Big R...|TV Episode       ...|  $4.07|2022-12-08 12:32:33|Home Video Rental...|Mcpherson and Son...|        Easton|Sell-Through Inco...|     Revenue|\n",
      "|       1416|Kayla            ...|Russell          ...|Jasmine's Trip in...|Movie            ...| $33.46|2023-05-13 10:06:09|Airports and Airl...|Jensen, Chaney an...|    Broomfield|Distribution Inco...|     Revenue|\n",
      "|        597|William          ...|Horne            ...|Denise's Date in ...|Single View Movie...|  $5.54|2023-07-17 12:31:39|Outdoor Events   ...|Atkinson, Jones a...|          Mesa|Rental Income Rev...|     Revenue|\n",
      "|       1655|Maxwell          ...|Coleman          ...|Kimberly's Great War|Movie            ...| $34.44|2023-06-27 03:01:38|Web Series Platfo...|Pearson-Adams    ...|    Burnsville|Interest Income R...|     Revenue|\n",
      "|        520|John             ...|Simpson          ...|Shelby's Date Wit...|Subscription     ...| $21.80|2022-12-03 12:02:00|Cable TV Networks...|Spence-Caldwell  ...| Oklahoma City|Music Income Reve...|     Revenue|\n",
      "|         77|Samantha         ...|Estrada          ...|Allen's Spy Thriller|Game             ...|  $5.99|2023-05-27 20:38:18|Theatrical       ...|Smith-Lawson     ...|       Chicago|Interest Income R...|     Revenue|\n",
      "|       1473|Brian            ...|Elliott          ...|Austin's Trip in ...|Single View Movie...| $17.37|2023-07-18 11:10:16|Home Video Rental...|Parker Inc       ...|    Petersburg|Theatrical Income...|     Revenue|\n",
      "|       1706|Robert           ...|Gibson           ...|Lauren's Trip in ...|Download         ...|  $5.07|2022-12-03 13:15:56|Music Publishing ...|Mann Group       ...|        Tulare|Distribution Inco...|     Revenue|\n",
      "|       1536|Jamie            ...|Summers          ...|Nancy's Trip in t...|Pay TV           ...|  $7.85|2023-06-26 13:55:14|Home Video DVD   ...|Mendoza Ltd      ...|    New Albany|Rental Income Rev...|     Revenue|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+-------+-------------------+--------------------+--------------------+--------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Overall Time: 0 minutes and 1 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "u = mutil()\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize a SparkSession\n",
    "spark = create_spark_sesssion()\n",
    "\n",
    "\n",
    "dbprod = db_base(\"products\")\n",
    "get_product_info_sql=dbprod.get_sql_query_from_query_key(\"get_product_info\")\n",
    "\n",
    "query= \"(\" + get_product_info_sql + \") AS query_table\"\n",
    "\n",
    "prod_info=test_sql_server_connection(query=query,spark=spark)\n",
    "\n",
    "\n",
    "dbfin = db_base(\"finance\",svr_type='postsql')\n",
    "\n",
    "get_account_activity = dbfin.get_sql_query_from_query_key(\"get_account_activity\")\n",
    "\n",
    "query= \"(\" + get_account_activity + \") AS query_table\"\n",
    "\n",
    "fin_account_activity=test_postgress_sql(query,spark)\n",
    "\n",
    "\n",
    "dbcust = db_base(\"customers\",svr_type='mysql')\n",
    "\n",
    "\n",
    "query = dbcust.get_sql_query_from_query_key(\"get_customer_product_history1\")\n",
    "\n",
    "query = \"(\" + query + \") AS query_table\"\n",
    "\n",
    "cust_products = test_mysql_server(query,spark)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming cust_products, prod_info, and fin_account_activity are already loaded as DataFrames\n",
    "# For example, they can be loaded from a source like this:\n",
    "# cust_products = spark.read.format(\"source_format\").load(\"path_to_cust_products\")\n",
    "# prod_info = spark.read.format(\"source_format\").load(\"path_to_prod_info\")\n",
    "# fin_account_activity = spark.read.format(\"source_format\").load(\"path_to_fin_account_activity\")\n",
    "\n",
    "# Register DataFrames as temporary views\n",
    "cust_products.createOrReplaceTempView(\"cust_products\")\n",
    "prod_info.createOrReplaceTempView(\"prod_info\")\n",
    "fin_account_activity.createOrReplaceTempView(\"fin_account_activity\")\n",
    "\n",
    "\n",
    "# SQL query\n",
    "sql_query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    cp.id AS customer_id,\n",
    "    cp.f_name,\n",
    "    cp.l_name,\n",
    "    p.product_name,\n",
    "    p.product_type,\n",
    "    fa.amt_usd,\n",
    "    fa.post_date,\n",
    "    fa.channel_desc,\n",
    "    fa.partner_desc,\n",
    "    fa.location_name,\n",
    "    fa.account_name,\n",
    "    fa.account_type\n",
    "FROM cust_products cp\n",
    "JOIN prod_info p ON p.id = cp.product_id\n",
    "JOIN fin_account_activity fa ON fa.customer_id = cp.id AND fa.product_id = cp.product_id\n",
    "'''\n",
    "\n",
    "# Execute SQL query\n",
    "result_df = spark.sql(sql_query)\n",
    "\n",
    "# Show the result\n",
    "result_df.show()\n",
    "\n",
    "# Stop the SparkSession when done\n",
    "spark.stop()\n",
    "\n",
    "\n",
    "# Stop the timer and calculate elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Convert elapsed time to minutes and seconds\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(f\"Overall Time: {minutes} minutes and {seconds} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bb8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b37c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
