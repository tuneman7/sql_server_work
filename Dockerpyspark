# Start from OpenJDK base image
FROM openjdk:11-jre-slim

# Install Python and necessary utilities
RUN apt-get update && \
    apt-get install -y python3 python3-pip wget tree unixodbc unixodbc-dev libpostgresql-jdbc-java zstd sudo iputils-ping && \
    apt-get upgrade -y && \
    apt-get clean;

# Set the working directory in the container
WORKDIR /workspace

# Create a directory for JDBC drivers
RUN mkdir -p /opt/jdbc_drivers

# Download JDBC Drivers for MSSQL, MySQL
RUN wget -O sqljdbc_12.4.2.0_enu.tar.gz https://go.microsoft.com/fwlink/?linkid=2247860
RUN tar xzf sqljdbc_12.4.2.0_enu.tar.gz
RUN mv sqljdbc_12.4 /usr/share/java/
RUN rm sqljdbc_12.4.2.0_enu.tar.gz 

#MYSQL
COPY /mysql-connector-j_8.2.0-1ubuntu22.04_all_repacked.deb .
RUN dpkg -i --force-overwrite mysql-connector-j_8.2.0-1ubuntu22.04_all_repacked.deb
RUN rm mysql-connector-j_8.2.0-1ubuntu22.04_all_repacked.deb

# Download JDBC Drivers for BigQuery
RUN wget -O spark-bigquery-latest_2.12.jar https://storage.googleapis.com/spark-lib/bigquery/spark-bigquery-latest_2.12.jar
RUN mv spark-bigquery-latest_2.12.jar /usr/share/java/



# Set environment variables for Spark
ENV SPARK_VERSION=3.5.0
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/spark
ENV PATH=$PATH:$SPARK_HOME/bin
ENV SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18080 -Dspark.eventLog.enabled=true -Dspark.eventLog.dir=/tmp/spark-events"
ENV SPARK_NO_DAEMONIZE=TRUE


# Setup Spark
RUN mkdir -p /tmp/spark-events
RUN chmod -R 777 /tmp/spark-events
RUN wget -q https://downloads.apache.org/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz && \
    tar xzf spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz && \
    mv spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION /spark && \
    rm spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz

# Install PySpark and Jupyter
RUN pip3 install pyspark==$SPARK_VERSION jupyter

#COPY THE ODBC CONNECTORS TO THE CORRECT LOCATION
RUN cp /usr/share/java/postgresql.jar /spark/jars/
RUN cp /usr/share/java/sqljdbc_12.4/enu/jars/mssql-jdbc-12.4.2.jre11.jar /spark/jars/
RUN cp /usr/share/java/mysql-connector-java-8.2.0.jar /spark/jars/


# Expose ports for Jupyter and Spark UI
EXPOSE 8888
EXPOSE 4040
EXPOSE 18080

COPY /pyspark_requirements.txt .
RUN pip install -r pyspark_requirements.txt

COPY start.sh /start.sh
RUN chmod +x /start.sh

CMD ["/bin/bash", "/start.sh"]

